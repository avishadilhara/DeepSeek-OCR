{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58cfc446",
   "metadata": {},
   "source": [
    "# DeepSeek-OCR with Tversky Neural Networks - Sinhala OCR\n",
    "\n",
    "This notebook trains DeepSeek-OCR enhanced with Tversky Projection layers for Sinhala OCR.\n",
    "\n",
    "**Dataset:**\n",
    "- Images: `/kaggle/input/sinhala-printed-text-dataset-400/images` (400 images)\n",
    "- Annotations: `/kaggle/input/sinhala-printed-text-dataset-400/annotations.csv`\n",
    "\n",
    "**Requirements:**\n",
    "- Kaggle GPU: T4 x2 or P100\n",
    "- RAM: 16GB+\n",
    "\n",
    "**Steps:**\n",
    "1. Environment Setup\n",
    "2. Load Tversky module\n",
    "3. Load base model\n",
    "4. Apply Tversky conversion\n",
    "5. Prepare Sinhala dataset\n",
    "6. Train with mixed precision\n",
    "7. Evaluate and save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b22954",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6363b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b60dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers>=4.37.0 accelerate>=0.25.0 bitsandbytes>=0.41.0\n",
    "!pip install -q datasets pillow tqdm\n",
    "!pip install -q ninja packaging pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef31160",
   "metadata": {},
   "source": [
    "## 2. Tversky Module Setup\n",
    "\n",
    "Option A: Clone from GitHub\n",
    "Option B: Upload tversky folder as Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4706caca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Clone from GitHub (replace with your repo)\n",
    "# !git clone https://github.com/YOUR_USERNAME/DeepSeek-OCR.git /kaggle/working/DeepSeek-OCR\n",
    "\n",
    "# Option B: If uploaded as Kaggle dataset named 'tversky-ocr-code'\n",
    "# !cp -r /kaggle/input/tversky-ocr-code/tversky /kaggle/working/\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add path based on your setup\n",
    "TVERSKY_PATHS = [\n",
    "    '/kaggle/working/DeepSeek-OCR/DeepSeek-OCR-master/DeepSeek-OCR-vllm',\n",
    "    '/kaggle/working',\n",
    "    '/kaggle/input/tversky-ocr-code'\n",
    "]\n",
    "\n",
    "for path in TVERSKY_PATHS:\n",
    "    if os.path.exists(path):\n",
    "        sys.path.insert(0, path)\n",
    "        print(f\"Added to path: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d48d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Tversky import\n",
    "try:\n",
    "    from tversky import (\n",
    "        TverskyProjection,\n",
    "        TverskyLMHead,\n",
    "        TverskyTrainingConfig,\n",
    "        SINHALA_OCR_TVERSKY_CONFIG,\n",
    "        create_tversky_optimizer,\n",
    "        get_tversky_regularization_loss,\n",
    "        monitor_tversky_health,\n",
    "        analyze_tversky_parameters\n",
    "    )\n",
    "    print(\"Tversky module imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "    print(\"Please upload the tversky folder or clone the repo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda4706c",
   "metadata": {},
   "source": [
    "## 3. Dataset Paths & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cda2b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# YOUR KAGGLE DATASET PATHS\n",
    "# ============================================\n",
    "KAGGLE_IMAGES_DIR = \"/kaggle/input/sinhala-printed-text-dataset-400/images\"\n",
    "KAGGLE_ANNOTATIONS_CSV = \"/kaggle/input/sinhala-printed-text-dataset-400/annotations.csv\"\n",
    "\n",
    "# Verify paths exist\n",
    "import os\n",
    "print(f\"Images directory exists: {os.path.exists(KAGGLE_IMAGES_DIR)}\")\n",
    "print(f\"Annotations file exists: {os.path.exists(KAGGLE_ANNOTATIONS_CSV)}\")\n",
    "\n",
    "if os.path.exists(KAGGLE_IMAGES_DIR):\n",
    "    images = os.listdir(KAGGLE_IMAGES_DIR)\n",
    "    print(f\"Number of images: {len(images)}\")\n",
    "    print(f\"Sample images: {images[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bfa33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the CSV file\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(KAGGLE_ANNOTATIONS_CSV)\n",
    "print(f\"CSV shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfac1fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "import os\n",
    "\n",
    "@dataclass\n",
    "class KaggleTrainingConfig:\n",
    "    \"\"\"Configuration optimized for Kaggle T4/P100 GPUs.\"\"\"\n",
    "    \n",
    "    # Dataset paths\n",
    "    images_dir: str = KAGGLE_IMAGES_DIR\n",
    "    annotations_csv: str = KAGGLE_ANNOTATIONS_CSV\n",
    "    \n",
    "    # CSV column names (update these based on your CSV structure)\n",
    "    image_col: str = 'image'  # Column containing image filenames\n",
    "    text_col: str = 'text'    # Column containing ground truth text\n",
    "    \n",
    "    # Model\n",
    "    model_name: str = \"deepseek-ai/deepseek-vl-1.3b-chat\"\n",
    "    use_4bit: bool = True\n",
    "    use_flash_attention: bool = False  # Set False if not supported\n",
    "    \n",
    "    # Tversky\n",
    "    num_features: int = 512\n",
    "    conversion_strategy: str = 'lm_head_only'\n",
    "    feature_activation: str = 'softplus'\n",
    "    use_smooth_min: bool = True\n",
    "    smooth_min_temperature: float = 0.5\n",
    "    init_alpha: float = 0.3\n",
    "    init_beta: float = 0.7\n",
    "    init_gamma: float = 15.0\n",
    "    \n",
    "    # Training - optimized for 400 samples\n",
    "    batch_size: int = 2          # Small for T4 16GB\n",
    "    gradient_accumulation_steps: int = 4  # Effective batch = 8\n",
    "    learning_rate: float = 5e-5\n",
    "    tversky_lr_multiplier: float = 0.05\n",
    "    num_epochs: int = 20         # More epochs for small dataset\n",
    "    warmup_ratio: float = 0.1\n",
    "    max_seq_length: int = 256    # Adjust based on your text lengths\n",
    "    \n",
    "    # Mixed precision\n",
    "    fp16: bool = True\n",
    "    bf16: bool = False\n",
    "    \n",
    "    # Regularization\n",
    "    diversity_weight: float = 0.02\n",
    "    sparsity_weight: float = 0.001\n",
    "    weight_decay: float = 0.01\n",
    "    max_grad_norm: float = 1.0\n",
    "    \n",
    "    # Validation split\n",
    "    val_split: float = 0.1  # 10% for validation (40 images)\n",
    "    \n",
    "    # Paths\n",
    "    output_dir: str = '/kaggle/working/outputs'\n",
    "    \n",
    "    # Logging\n",
    "    logging_steps: int = 10\n",
    "    eval_steps: int = 50\n",
    "    save_steps: int = 100\n",
    "\n",
    "config = KaggleTrainingConfig()\n",
    "\n",
    "os.makedirs(config.output_dir, exist_ok=True)\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "for k, v in vars(config).items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7827dd",
   "metadata": {},
   "source": [
    "## 4. Dataset Class for CSV Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160d9ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class SinhalaOCRDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for Sinhala OCR with CSV annotations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        images_dir: str,\n",
    "        annotations_csv: str,\n",
    "        tokenizer,\n",
    "        image_col: str = 'image',\n",
    "        text_col: str = 'text',\n",
    "        max_length: int = 256,\n",
    "        image_size: tuple = (384, 384)\n",
    "    ):\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        # Load CSV\n",
    "        df = pd.read_csv(annotations_csv)\n",
    "        \n",
    "        # Auto-detect columns if needed\n",
    "        if image_col not in df.columns:\n",
    "            for col in ['image', 'image_name', 'filename', 'file', 'img', 'Image', 'path']:\n",
    "                if col in df.columns:\n",
    "                    image_col = col\n",
    "                    break\n",
    "            else:\n",
    "                image_col = df.columns[0]\n",
    "                \n",
    "        if text_col not in df.columns:\n",
    "            for col in ['text', 'label', 'ground_truth', 'gt', 'Text', 'annotation', 'transcription']:\n",
    "                if col in df.columns:\n",
    "                    text_col = col\n",
    "                    break\n",
    "            else:\n",
    "                text_col = df.columns[1]\n",
    "        \n",
    "        print(f\"Using columns: image='{image_col}', text='{text_col}'\")\n",
    "        \n",
    "        # Create samples list\n",
    "        self.samples = []\n",
    "        missing_count = 0\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            img_name = str(row[image_col])\n",
    "            text = str(row[text_col])\n",
    "            \n",
    "            # Try to find image file\n",
    "            img_path = self.images_dir / img_name\n",
    "            \n",
    "            if not img_path.exists():\n",
    "                # Try common extensions\n",
    "                for ext in ['', '.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']:\n",
    "                    test_path = self.images_dir / f\"{img_name}{ext}\"\n",
    "                    if test_path.exists():\n",
    "                        img_path = test_path\n",
    "                        break\n",
    "            \n",
    "            if img_path.exists():\n",
    "                self.samples.append({'image_path': img_path, 'text': text})\n",
    "            else:\n",
    "                missing_count += 1\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} samples\")\n",
    "        if missing_count > 0:\n",
    "            print(f\"Warning: {missing_count} images not found\")\n",
    "        \n",
    "        # Image transforms\n",
    "        self.transform = T.Compose([\n",
    "            T.Resize(image_size),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Load and transform image\n",
    "        image = Image.open(sample['image_path']).convert('RGB')\n",
    "        pixel_values = self.transform(image)\n",
    "        \n",
    "        # Tokenize text\n",
    "        text = sample['text']\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'pixel_values': pixel_values,\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': encoding['input_ids'].squeeze(0).clone()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec17d47",
   "metadata": {},
   "source": [
    "## 5. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acdce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "def load_model(config):\n",
    "    \"\"\"Load model with memory-efficient settings.\"\"\"\n",
    "    \n",
    "    if config.use_4bit:\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "        )\n",
    "    else:\n",
    "        bnb_config = None\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        config.model_name,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        config.model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16 if config.fp16 else torch.float32,\n",
    "    )\n",
    "    \n",
    "    model.gradient_checkpointing_enable()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "print(\"Loading model...\")\n",
    "model, tokenizer = load_model(config)\n",
    "print(f\"Model loaded\")\n",
    "print(f\"  Vocab size: {model.config.vocab_size}\")\n",
    "print(f\"  Hidden size: {model.config.hidden_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b378a2",
   "metadata": {},
   "source": [
    "## 6. Apply Tversky Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from tversky import TverskyLMHead\n",
    "\n",
    "def convert_to_tversky(model, config):\n",
    "    \"\"\"Convert LM head to Tversky projection.\"\"\"\n",
    "    \n",
    "    hidden_size = model.config.hidden_size\n",
    "    vocab_size = model.config.vocab_size\n",
    "    \n",
    "    # Find LM head\n",
    "    lm_head_attr = None\n",
    "    old_lm_head = None\n",
    "    \n",
    "    for name in ['lm_head', 'output', 'cls']:\n",
    "        if hasattr(model, name):\n",
    "            old_lm_head = getattr(model, name)\n",
    "            lm_head_attr = name\n",
    "            break\n",
    "    \n",
    "    if old_lm_head is None:\n",
    "        print(\"Could not find LM head. Model structure:\")\n",
    "        for name, module in model.named_children():\n",
    "            print(f\"  {name}: {type(module).__name__}\")\n",
    "        return model\n",
    "    \n",
    "    old_params = sum(p.numel() for p in old_lm_head.parameters())\n",
    "    \n",
    "    # Create Tversky head\n",
    "    new_lm_head = TverskyLMHead(\n",
    "        hidden_size=hidden_size,\n",
    "        vocab_size=vocab_size,\n",
    "        num_features=config.num_features,\n",
    "        init_from_linear=old_lm_head if isinstance(old_lm_head, nn.Linear) else None,\n",
    "        feature_activation=config.feature_activation,\n",
    "        use_smooth_min=config.use_smooth_min,\n",
    "        smooth_min_temperature=config.smooth_min_temperature,\n",
    "        init_alpha=config.init_alpha,\n",
    "        init_beta=config.init_beta,\n",
    "        init_gamma=config.init_gamma\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    device = next(old_lm_head.parameters()).device\n",
    "    dtype = next(old_lm_head.parameters()).dtype\n",
    "    new_lm_head = new_lm_head.to(device=device, dtype=dtype)\n",
    "    \n",
    "    setattr(model, lm_head_attr, new_lm_head)\n",
    "    \n",
    "    new_params = sum(p.numel() for p in new_lm_head.parameters())\n",
    "    \n",
    "    print(f\"\\nTversky conversion complete:\")\n",
    "    print(f\"  Original params: {old_params:,}\")\n",
    "    print(f\"  Tversky params: {new_params:,}\")\n",
    "    print(f\"  Reduction: {(1 - new_params/old_params)*100:.1f}%\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = convert_to_tversky(model, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9726feb",
   "metadata": {},
   "source": [
    "## 7. Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1558335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "full_dataset = SinhalaOCRDataset(\n",
    "    images_dir=config.images_dir,\n",
    "    annotations_csv=config.annotations_csv,\n",
    "    tokenizer=tokenizer,\n",
    "    image_col=config.image_col,\n",
    "    text_col=config.text_col,\n",
    "    max_length=config.max_seq_length\n",
    ")\n",
    "\n",
    "# Split into train/val\n",
    "val_size = int(len(full_dataset) * config.val_split)\n",
    "train_size = len(full_dataset) - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_dataset, \n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset split:\")\n",
    "print(f\"  Train: {len(train_dataset)} samples\")\n",
    "print(f\"  Val: {len(val_dataset)} samples\")\n",
    "\n",
    "# Create loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07300a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(\"Sample batch shapes:\")\n",
    "for k, v in sample_batch.items():\n",
    "    print(f\"  {k}: {v.shape}\")\n",
    "\n",
    "# Decode a sample\n",
    "sample_text = tokenizer.decode(sample_batch['input_ids'][0], skip_special_tokens=True)\n",
    "print(f\"\\nSample text: {sample_text[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d3933",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5536b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tversky import create_tversky_optimizer, get_tversky_regularization_loss, monitor_tversky_health, analyze_tversky_parameters\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, config, train_loader, val_loader):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = next(model.parameters()).device\n",
    "        \n",
    "        # Optimizer\n",
    "        self.optimizer = create_tversky_optimizer(\n",
    "            model,\n",
    "            base_lr=config.learning_rate,\n",
    "            tversky_lr_multiplier=config.tversky_lr_multiplier,\n",
    "            weight_decay=config.weight_decay\n",
    "        )\n",
    "        \n",
    "        # Scheduler\n",
    "        total_steps = len(train_loader) * config.num_epochs // config.gradient_accumulation_steps\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.optimizer, T_max=total_steps\n",
    "        )\n",
    "        \n",
    "        # Mixed precision\n",
    "        self.scaler = GradScaler() if config.fp16 else None\n",
    "        \n",
    "        # Tracking\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.history = {'train_loss': [], 'val_loss': [], 'val_accuracy': []}\n",
    "        \n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "        \n",
    "        for step, batch in enumerate(pbar):\n",
    "            input_ids = batch['input_ids'].to(self.device)\n",
    "            attention_mask = batch['attention_mask'].to(self.device)\n",
    "            labels = batch['labels'].to(self.device)\n",
    "            \n",
    "            if self.config.fp16:\n",
    "                with autocast():\n",
    "                    outputs = self.model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels\n",
    "                    )\n",
    "                    loss = outputs.loss\n",
    "                    reg_loss = get_tversky_regularization_loss(\n",
    "                        self.model,\n",
    "                        self.config.diversity_weight,\n",
    "                        self.config.sparsity_weight\n",
    "                    )\n",
    "                    loss = (loss + reg_loss) / self.config.gradient_accumulation_steps\n",
    "                \n",
    "                self.scaler.scale(loss).backward()\n",
    "            else:\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                loss = outputs.loss\n",
    "                reg_loss = get_tversky_regularization_loss(\n",
    "                    self.model,\n",
    "                    self.config.diversity_weight,\n",
    "                    self.config.sparsity_weight\n",
    "                )\n",
    "                loss = (loss + reg_loss) / self.config.gradient_accumulation_steps\n",
    "                loss.backward()\n",
    "            \n",
    "            total_loss += loss.item() * self.config.gradient_accumulation_steps\n",
    "            \n",
    "            if (step + 1) % self.config.gradient_accumulation_steps == 0:\n",
    "                if self.config.fp16:\n",
    "                    self.scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.max_grad_norm)\n",
    "                    self.scaler.step(self.optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.max_grad_norm)\n",
    "                    self.optimizer.step()\n",
    "                \n",
    "                self.scheduler.step()\n",
    "                self.optimizer.zero_grad()\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{total_loss/(step+1):.4f}'})\n",
    "        \n",
    "        return total_loss / len(self.train_loader)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_tokens = 0\n",
    "        \n",
    "        for batch in self.val_loader:\n",
    "            input_ids = batch['input_ids'].to(self.device)\n",
    "            attention_mask = batch['attention_mask'].to(self.device)\n",
    "            labels = batch['labels'].to(self.device)\n",
    "            \n",
    "            outputs = self.model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            total_loss += outputs.loss.item()\n",
    "            \n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "            mask = labels != -100\n",
    "            total_correct += ((predictions == labels) & mask).sum().item()\n",
    "            total_tokens += mask.sum().item()\n",
    "        \n",
    "        return {\n",
    "            'loss': total_loss / len(self.val_loader),\n",
    "            'accuracy': total_correct / total_tokens if total_tokens > 0 else 0\n",
    "        }\n",
    "    \n",
    "    def train(self):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Starting training - {self.config.num_epochs} epochs\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        for epoch in range(self.config.num_epochs):\n",
    "            train_loss = self.train_epoch(epoch)\n",
    "            val_metrics = self.evaluate()\n",
    "            \n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['val_loss'].append(val_metrics['loss'])\n",
    "            self.history['val_accuracy'].append(val_metrics['accuracy'])\n",
    "            \n",
    "            # Print summary\n",
    "            print(f\"\\nEpoch {epoch+1}/{self.config.num_epochs}:\")\n",
    "            print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"  Val Loss: {val_metrics['loss']:.4f}\")\n",
    "            print(f\"  Val Accuracy: {val_metrics['accuracy']*100:.2f}%\")\n",
    "            \n",
    "            # Tversky analysis\n",
    "            analysis = analyze_tversky_parameters(self.model)\n",
    "            for name, params in analysis.items():\n",
    "                print(f\"  {name}: a={params['alpha']:.3f}, b={params['beta']:.3f}, g={params['gamma']:.3f}\")\n",
    "            \n",
    "            # Check health\n",
    "            warnings = monitor_tversky_health(self.model)\n",
    "            if warnings:\n",
    "                print(f\"  Warnings: {warnings}\")\n",
    "            \n",
    "            # Save best\n",
    "            if val_metrics['loss'] < self.best_val_loss:\n",
    "                self.best_val_loss = val_metrics['loss']\n",
    "                self.save('best_model.pt')\n",
    "                print(f\"  Saved best model\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training complete! Best val loss: {self.best_val_loss:.4f}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        return self.history\n",
    "    \n",
    "    def save(self, filename):\n",
    "        path = os.path.join(self.config.output_dir, filename)\n",
    "        tversky_state = {}\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if any(k in name for k in ['alpha_raw', 'beta_raw', 'gamma', 'feature_bank', 'prototype_bank']):\n",
    "                tversky_state[name] = param.data.cpu()\n",
    "        \n",
    "        torch.save({\n",
    "            'tversky_state_dict': tversky_state,\n",
    "            'config': vars(self.config),\n",
    "            'history': self.history,\n",
    "            'best_val_loss': self.best_val_loss\n",
    "        }, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c967b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer and train\n",
    "trainer = Trainer(model, config, train_loader, val_loader)\n",
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a6d9d6",
   "metadata": {},
   "source": [
    "## 9. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e88537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train')\n",
    "axes[0].plot(history['val_loss'], label='Validation')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training & Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot([acc * 100 for acc in history['val_accuracy']])\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Validation Accuracy')\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{config.output_dir}/training_curves.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3df89f5",
   "metadata": {},
   "source": [
    "## 10. Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a few validation samples\n",
    "@torch.no_grad()\n",
    "def test_samples(model, tokenizer, val_dataset, num_samples=5):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    print(\"\\nSample Predictions:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i in range(min(num_samples, len(val_dataset))):\n",
    "        sample = val_dataset[i]\n",
    "        \n",
    "        input_ids = sample['input_ids'].unsqueeze(0).to(device)\n",
    "        \n",
    "        # Get prediction\n",
    "        outputs = model(input_ids=input_ids)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        \n",
    "        # Decode\n",
    "        ground_truth = tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
    "        predicted = tokenizer.decode(predictions[0], skip_special_tokens=True)\n",
    "        \n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        print(f\"  Ground Truth: {ground_truth[:100]}\")\n",
    "        print(f\"  Predicted:    {predicted[:100]}\")\n",
    "\n",
    "test_samples(model, tokenizer, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99475306",
   "metadata": {},
   "source": [
    "## 11. Save & Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23460c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List output files\n",
    "print(\"\\nOutput files:\")\n",
    "for f in os.listdir(config.output_dir):\n",
    "    filepath = os.path.join(config.output_dir, f)\n",
    "    size_mb = os.path.getsize(filepath) / 1e6\n",
    "    print(f\"  {f} ({size_mb:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182257dd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "### CSV Column Names\n",
    "Update `config.image_col` and `config.text_col` if your CSV has different column names.\n",
    "\n",
    "### Memory Issues\n",
    "If you get OOM errors:\n",
    "1. Reduce `batch_size` to 1\n",
    "2. Increase `gradient_accumulation_steps`\n",
    "3. Reduce `max_seq_length`\n",
    "\n",
    "### After Training\n",
    "1. Download `best_model.pt` from Output tab\n",
    "2. Use it to initialize Tversky layers for inference"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
